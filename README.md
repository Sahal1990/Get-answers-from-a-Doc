# ğŸš€ Simple Groq RAG Pipeline  
### *Retrieval-Augmented Generation with Dynamic Chunking + Multilingual Question Support*

This project implements a **minimal, clean, and production-ready RAG (Retrieval-Augmented Generation)** pipeline using:

- **Groqâ€™s OpenAI-compatible Responses API**  
- **`openai/gpt-oss-120b` model**  
- **SentenceTransformers embeddings**  
- **FAISS similarity search**

You can upload *any* document and then ask questions like:

- **â€œSummarize this document.â€**  
- **â€œIs document ka summary kya hai?â€** (Hindi)  
- **â€œÂ¿CuÃ¡l es el punto principal del documento?â€** (Spanish)

The pipeline automatically retrieves the most relevant chunks from the document and sends them to an LLM for grounded question answering.

---

## ğŸŒŸ Key Features

### ğŸ”¹ **1. Dynamic Chunking**
Instead of fixed-size splits, the system uses **configurable chunk size + overlap**, allowing:

- Better semantic grouping  
- Reduced hallucinations  
- More accurate retrieval  
- Flexibility across different document types  

Modify these easily via environment variables:

```env
CHUNK_SIZE=700
CHUNK_OVERLAP=150
